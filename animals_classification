{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":840806,"sourceType":"datasetVersion","datasetId":59760},{"sourceId":12277039,"sourceType":"datasetVersion","datasetId":7736751}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Proyek Klasifikasi Gambar: [Animals-10]\n- Nama: [Damar Syarafi Ramadhan]\n- Email: [damarsyarafi.rmdhn@gmail.com]\n- ID Dicoding: [maresan]\n- Dataset : [Animal-10] https://www.kaggle.com/datasets/alessiocorrado99/animals10","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"id":"mdidIMGHL-KL","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport zipfile,os\nfrom PIL import Image\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.applications.mobilenet_v2 import preprocess_input\nfrom tensorflow.keras import layers, models, regularizers\n\n# Mengabaikan peringatan\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)","metadata":{"trusted":true,"id":"ICmWExzaRwBo"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport shutil\n\n# Folder containing the directories you want to rename (the original read-only path)\nread_only_base_path = \"/kaggle/input/animals10\"\n# Writable path to copy the data to\nwritable_base_path = \"/kaggle/working/animals10-translated\"\n\n# Create the writable directory if it doesn't exist\nos.makedirs(writable_base_path, exist_ok=True)\n\n# Copy the contents from the read-only directory to the writable directory\nprint(f\"Copying data from {read_only_base_path} to {writable_base_path}...\")\nfor item in os.listdir(read_only_base_path):\n    s = os.path.join(read_only_base_path, item)\n    d = os.path.join(writable_base_path, item)\n    if os.path.isdir(s):\n        shutil.copytree(s, d, symlinks=False, ignore_dangling_symlinks=True)\n    else:\n        shutil.copy2(s, d)\nprint(\"Copying complete.\")","metadata":{"trusted":true,"id":"VZ4S_lFcRwBp","outputId":"cc79a272-15d9-4814-d05b-c0914fb7ed82","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Translation dictionary\ntranslate = {\n    \"cane\": \"dog\", \"cavallo\": \"horse\", \"elefante\": \"elephant\", \"farfalla\": \"butterfly\",\n    \"gallina\": \"chicken\", \"gatto\": \"cat\", \"mucca\": \"cow\", \"ragno\": \"spider\", \"pecora\": \"sheep\", \"scoiattolo\": \"squirrel\",\n    \"dog\": \"cane\", \"horse\": \"cavallo\", \"elephant\": \"elefante\", \"butterfly\": \"farfalla\",\n    \"chicken\": \"gallina\", \"cat\": \"gatto\", \"cow\": \"mucca\", \"spider\": \"ragno\", \"squirrel\": \"scoiattolo\"\n}\nwritable_base_path = \"/kaggle/working/animals10-translated/raw-img\"\n\n# Now list all folders in the writable_base_path and rename them\nfor folder in os.listdir(writable_base_path):\n    folder_path = os.path.join(writable_base_path, folder)\n    if os.path.isdir(folder_path):\n        new_name = translate.get(folder)\n        if new_name:\n            new_path = os.path.join(writable_base_path, new_name)\n            # Check if the target folder already exists in the writable path\n            if not os.path.exists(new_path):\n                os.rename(folder_path, new_path)\n                print(f\"Renamed '{folder}' to '{new_name}' in writable directory\")\n            else:\n                print(f\"Target folder '{new_name}' already exists in writable directory. Skipping.\")\n\n# Update the `base_path` variable if you plan to use it later with the renamed directories\nbase_path = writable_base_path\nprint(f\"Updated base_path to: {base_path}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SlG_S9QXNE4u","outputId":"10a5332b-aeb6-4d41-d326-2bd61a952ba2","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dir = '/kaggle/working/animals-image-data/train'\nval_dir = '/kaggle/working/animals-image-data/valid'\ntest_dir = '/kaggle/working/animals-image-data/test'","metadata":{"id":"lxZ699wTSdQ3","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport shutil\nimport random\n\ndef split_data(source, train, validation, test, split_size):\n  for class_name in os.listdir(source):\n    class_source_dir = os.path.join(source, class_name)\n    class_train_dir = os.path.join(train, class_name)\n    class_val_dir = os.path.join(validation, class_name)\n    class_test_dir = os.path.join(test, class_name)\n\n    # Create class subdirectories in destination folders\n    os.makedirs(class_train_dir, exist_ok=True)\n    os.makedirs(class_val_dir, exist_ok=True)\n    os.makedirs(class_test_dir, exist_ok=True)\n\n    files = [f for f in os.listdir(class_source_dir) if os.path.isfile(os.path.join(class_source_dir, f))]\n    random.shuffle(files)\n\n    # Calculate split indices based on the desired ratios\n    total_files = len(files)\n    train_split = int(total_files * split_size[0])  # 0.7\n    val_split = int(total_files * split_size[1])  # 0.1\n    # Split the files into train, validation, and test sets\n    train_files = files[:train_split]\n    val_files = files[train_split : train_split + val_split]\n    test_files = files[train_split + val_split :]  # edit\n\n    for filename in train_files:\n      shutil.copy(os.path.join(class_source_dir, filename), os.path.join(class_train_dir, filename))\n    for filename in val_files:\n      shutil.copy(os.path.join(class_source_dir, filename), os.path.join(class_val_dir, filename))\n    for filename in test_files:\n      shutil.copy(os.path.join(class_source_dir, filename), os.path.join(class_test_dir, filename))\n\n# Example usage:\nsplit_data(writable_base_path, train_dir, val_dir, test_dir, (0.7, 0.15))\nprint(\"Data Split Successfully\")","metadata":{"id":"sjNg85YwSjdh","outputId":"bacfb440-3422-468a-8cc0-ea863c57417b","trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pillow for image processing\nfrom PIL import Image\n\n# Getting sample apple image\nimg_path = '/kaggle/input/animals10/raw-img/cane/OIF-e2bexWrojgtQnAPPcUfOWQ.jpeg'\nimg = Image.open(img_path)\nprint(\"image dimensions:\",img.size)\nimg\n\nplt.figure()\nplt.imshow(img)\nplt.colorbar()\nplt.grid(False)\nplt.show()","metadata":{"id":"_nktLxdlTyby","outputId":"992f0db4-b7a4-4fb6-a274-220c2cd6a961","trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":433}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"batch_size = 32\ntarget_size = (224, 224)\n\ntrain_generator = tf.keras.utils.image_dataset_from_directory(\n    train_dir,\n    labels='inferred',\n    label_mode='categorical',\n    image_size=target_size,\n    interpolation='nearest',\n    batch_size=batch_size,\n    shuffle=True\n)\n\nvalid_generator = tf.keras.utils.image_dataset_from_directory(\n    val_dir,\n    labels='inferred',\n    label_mode='categorical',\n    image_size=target_size,\n    interpolation='nearest',\n    batch_size=batch_size,\n    shuffle=False\n)\n\ntest_generator = tf.keras.utils.image_dataset_from_directory(\n    test_dir,\n    labels='inferred',\n    label_mode='categorical',\n    image_size=target_size,\n    interpolation='nearest',\n    batch_size=batch_size,\n    shuffle=False\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AtPTRyNrJsjh","outputId":"73f0e28b-71b8-475d-d640-b18c73eadb25","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def cutout(image, size=32):\n    \"\"\"Implementasi Cutout untuk augmentasi gambar.\"\"\"\n    original_dtype = image.dtype\n    image = tf.cast(image, tf.float32)\n\n    shape = tf.shape(image)\n    h, w = shape[1], shape[2]\n\n    y = tf.random.uniform([], 0, h, dtype=tf.int32)\n    x = tf.random.uniform([], 0, w, dtype=tf.int32)\n\n    y1 = tf.clip_by_value(y - size // 2, 0, h)\n    y2 = tf.clip_by_value(y + size // 2, 0, h)\n    x1 = tf.clip_by_value(x - size // 2, 0, w)\n    x2 = tf.clip_by_value(x + size // 2, 0, w)\n\n    y_indices = tf.range(h)\n    x_indices = tf.range(w)\n    y_grid, x_grid = tf.meshgrid(y_indices, x_indices, indexing='ij')\n\n    cutout_condition = ((y_grid >= y1) & (y_grid < y2) &\n                        (x_grid >= x1) & (x_grid < x2))\n    cutout_mask = tf.cast(~cutout_condition, tf.float32)\n\n    cutout_mask = tf.expand_dims(cutout_mask, axis=-1)\n    result = image * cutout_mask\n    return tf.cast(result, original_dtype)\n\ndef get_augmented_dataset(ds, augment=True):\n    \"\"\"Menerapkan augmentasi standar dan cutout ke dataset.\"\"\"\n    if augment:\n        augmentation = tf.keras.Sequential([\n            layers.RandomFlip(\"horizontal_and_vertical\"),\n            layers.RandomRotation(0.2),\n            layers.RandomZoom(0.15),\n            layers.RandomContrast(0.1),\n            layers.RandomBrightness(0.1),\n        ])\n\n        def apply_augmentation(x, y):\n            # Cast ke float32 sebelum augmentasi karena augmentation layer mungkin membutuhkan float32\n            x = tf.cast(x, tf.float32)\n            x_aug = augmentation(x)\n\n            # Terapkan Cutout dengan probabilitas 50%\n            cutout_prob = tf.random.uniform([]) < 0.5\n            x_final = tf.cond(\n                cutout_prob,\n                true_fn=lambda: cutout(x_aug), # Gunakan lambda untuk pemanggilan fungsi\n                false_fn=lambda: x_aug        # Gunakan lambda untuk pemanggilan fungsi\n            )\n            # Kembali ke dtype yang ditetapkan oleh mixed precision policy\n            x_final = tf.cast(x_final, tf.keras.mixed_precision.global_policy().compute_dtype)\n            return x_final, y\n\n        return ds.map(apply_augmentation, num_parallel_calls=tf.data.AUTOTUNE)\n    return ds\n\n# Terapkan augmentasi dan optimasi pipeline dataset (cache & prefetch)\ntrain_ds_aug = get_augmented_dataset(train_generator, augment=True) \\\n                .cache() \\\n                .prefetch(tf.data.AUTOTUNE)\n\nval_ds = valid_generator.cache().prefetch(tf.data.AUTOTUNE)\ntest_ds = test_generator.cache().prefetch(tf.data.AUTOTUNE)","metadata":{"id":"VTx0OGg1LwiY","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def verify_pixel_range(ds, name):\n    min_val, max_val, mean_val = float('inf'), float('-inf'), 0.0\n    total_pixels = 0\n\n    for images, _ in ds.take(3):  # Ambil 3 batch pertama\n        img_np = images.numpy()\n        min_val = min(min_val, img_np.min())\n        max_val = max(max_val, img_np.max())\n        mean_val += img_np.sum()\n        total_pixels += np.prod(img_np.shape)\n\n    mean_val /= total_pixels\n\n    print(f\"\\n{name} pixel range:\")\n    print(f\"Min: {min_val:.4f}\")\n    print(f\"Max: {max_val:.4f}\")\n    print(f\"Mean: {mean_val:.4f}\")\n\nverify_pixel_range(train_ds_aug, \"Training\")\nverify_pixel_range(val_ds, \"Validation\")\nverify_pixel_range(test_ds, \"Test\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_names = train_generator.class_names\nprint(class_names)\nnum_class = len(class_names)","metadata":{"id":"rRYrxVGhUgr1","outputId":"78bf03a1-e6cd-4e67-97e8-f49ae2bb5579","trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#tf.keras.backend.clear_session()","metadata":{"trusted":true,"id":"WQ8_jhv1LCzR"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.optimizers import Adam\n\nmodel = tf.keras.Sequential([\n    Conv2D(64, kernel_size=(3, 3), kernel_initializer='he_uniform', padding='same', activation='relu', input_shape=(224, 224, 3)),\n    BatchNormalization(),\n    MaxPooling2D((2,2)),\n    Conv2D(64, kernel_size=(3, 3), activation='relu', kernel_regularizer=l2(1e-4)),\n    BatchNormalization(),\n    MaxPooling2D((2,2)),\n    Conv2D(64, kernel_size=(3, 3), activation='relu', kernel_regularizer=l2(1e-4)),\n    BatchNormalization(),\n    MaxPooling2D((2,2)),\n\n    Conv2D(128, kernel_size=(3, 3), activation='relu', kernel_regularizer=l2(1e-4)),\n    BatchNormalization(),\n    MaxPooling2D((2,2)),\n    Conv2D(128, kernel_size=(3, 3), activation='relu', kernel_regularizer=l2(1e-4)),\n    BatchNormalization(),\n    MaxPooling2D((2,2)),\n    Conv2D(128, kernel_size=(3, 3), activation='relu', kernel_regularizer=l2(1e-4)),\n    BatchNormalization(),\n    MaxPooling2D((2,2)),\n\n    GlobalAveragePooling2D(),\n    BatchNormalization(),\n    Dropout(0.4),\n    Dense(128, activation='relu', kernel_regularizer=l2(1e-4)),\n    BatchNormalization(),\n    Dropout(0.2),\n    Dense(num_class, activation='softmax')\n])\n\nmodel.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel.summary()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"4cBoa_DdNeV7","outputId":"5ebc92fa-b5f2-40c2-9967-7d2f3bb440d7","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Membuat direktori checkpoint model\ncheckpoint_path = \"/kaggle/working/train_cnn/model.keras\"\ncheckpoint_dir = os.path.dirname(checkpoint_path)\n\n# Create a callback that saves the model's weights\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n                                                 monitor='val_accuracy',\n                                                 mode='max',\n                                                 save_freq='epoch',\n                                                 verbose=1)","metadata":{"id":"mFaFHLyqO8xR","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"earlystop = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss',\n    patience=10,\n    restore_best_weights=True\n)","metadata":{"id":"9SmnDhAkPCWN","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from keras.callbacks import ReduceLROnPlateau\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.0001, patience=5, min_lr=0.0001, verbose=1)","metadata":{"id":"qZxXHAXZPEmh","colab":{"base_uri":"https://localhost:8080/","height":36},"outputId":"8cdb1994-355d-4856-a846-2c03a547c78a","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate the number of steps per epoch and validation steps\ntrain_steps_per_epoch = tf.data.experimental.cardinality(train_ds_aug).numpy()\nval_steps_per_epoch = tf.data.experimental.cardinality(val_ds).numpy()\n\nhistory = model.fit(\n      train_ds_aug,\n      steps_per_epoch=train_steps_per_epoch,  # berapa batch yang akan dieksekusi pada setiap epoch\n      epochs=32,\n      validation_data=val_ds, # menampilkan akurasi pengujian data validasi\n      validation_steps=val_steps_per_epoch,  # berapa batch yang akan dieksekusi pada setiap epoch\n      verbose=1,\n      callbacks=[earlystop, checkpoint])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j2mTd-6wQAKQ","outputId":"5ec56be4-b7a9-49ac-d2e5-51c5ad648669","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Evaluasi\ntest_loss, test_acc = model.evaluate(test_ds)\nprint(f\"Test Accuracy: {test_acc:.4f}\")\n\n# Define accuracy and loss\nacc = history.history['accuracy']\nval_acc = history.history.get('val_accuracy', [])\nloss = history.history['loss']\nval_loss = history.history.get('val_loss', [])\n\n# Ambil panjang minimal\nmin_len = min(len(acc), len(val_acc), len(loss), len(val_loss))\nepochs = range(min_len)\n\n# Potong agar sama panjang\nacc = acc[:min_len]\nval_acc = val_acc[:min_len]\nloss = loss[:min_len]\nval_loss = val_loss[:min_len]\n\n# Plotting\nfig, ax = plt.subplots(1, 2, figsize=(12, 4))\n\n# Accuracy\nax[0].plot(epochs, acc, 'r', label='Training Accuracy')\nax[0].plot(epochs, val_acc, 'b', label='Validation Accuracy')\nax[0].set_title('Training and Validation Accuracy CNN')\nax[0].set_xlabel('Epoch')\nax[0].set_ylabel('Accuracy')\nax[0].legend(loc='upper left')\n\n# Loss\nax[1].plot(epochs, loss, 'r', label='Training Loss')\nax[1].plot(epochs, val_loss, 'b', label='Validation Loss')\nax[1].set_title('Training and Validation Loss CNN')\nax[1].set_xlabel('Epoch')\nax[1].set_ylabel('Loss')\nax[1].legend(loc='upper left')\n\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":447},"id":"0g2Vji-1QG3X","outputId":"65be97ef-f7cd-4003-b6ad-10fd8dacc226","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report\n\n# Inisialisasi list untuk menyimpan label sebenarnya (y_true) dan prediksi (y_pred)\ny_true = []\ny_pred = []\n\n# Lakukan prediksi pada dataset testing\n# Iterasi melalui setiap batch dalam test_ds\nfor images, labels in test_ds:\n    # Lakukan prediksi menggunakan model Anda\n    # verbose=0 agar tidak mencetak progress bar per batch\n    preds = model.predict(images, verbose=0)\n    # Konversi label sebenarnya (one-hot encoded) ke indeks kelas\n    y_true.extend(np.argmax(labels.numpy(), axis=1))\n    # Konversi prediksi (probabilitas) ke indeks kelas dengan probabilitas tertinggi\n    y_pred.extend(np.argmax(preds, axis=1))\n\n# Konversi list ke numpy array untuk perhitungan metrik\ny_true = np.array(y_true)\ny_pred = np.array(y_pred)\n\n# ========== Confusion Matrix ==========\n# Hitung Confusion Matrix\ncm = confusion_matrix(y_true, y_pred)\n\n# Buat DataFrame untuk visualisasi yang lebih baik dengan nama kelas\ndf_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n\n# Visualisasikan Confusion Matrix menggunakan seaborn heatmap\n\nplt.figure(figsize=(10, 7)) # Atur ukuran plot\nsns.heatmap(df_cm, annot=True, fmt='d', cmap='Blues', cbar=False, linewidths=.5, linecolor='black')\nplt.xlabel('Predicted Label', fontsize=14)\nplt.ylabel('True Label', fontsize=14)\n\nplt.title('Confusion Matrix', fontsize=16)\nplt.xticks(rotation=45, ha='right') # Putar label sumbu x agar tidak tumpang tindih\nplt.yticks(rotation=0) # Pastikan label sumbu y tetap horizontal\nplt.tight_layout() # Sesuaikan layout\n\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":514},"id":"1vxwrxgjQJst","outputId":"bb37b0c7-0508-43eb-c02b-d8092b377a85","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ========== Classification Report ==========\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_true, y_pred, target_names=class_names))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xPRZG4_zQMJB","outputId":"ecc90d72-ef95-4952-9cd7-0cef722c9c72","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras import layers, models, regularizers\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.applications.mobilenet import preprocess_input\nimport tensorflow as tf\n\n# Load base model\nbase_model = MobileNetV2(include_top=False, weights='imagenet', input_shape=(224 , 224, 3))\noutput_base_model_shape = base_model.output_shape\nbase_model.trainable = False\n\n# Let's take a look to see how many layers are in the base model\nprint(\"Number of layers in the base model: \", len(base_model.layers))\n\n# Fine-tune from this layer onwards\n#fine_tune_at = 100\n\n# Freeze all the layers before the `fine_tune_at` layer\n#for layer in base_model.layers[:fine_tune_at]:\n#  layer.trainable = False","metadata":{"id":"jq0tP-l003De","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8a7232b9-b9c8-48f7-a035-d4eee19e4007","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Definisi Model\nmodel = models.Sequential([\n    layers.Input(shape=(224, 224, 3)),\n    layers.Lambda(preprocess_input, name='mobilenet_preprocess'),\n    base_model,\n    \n    layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001)),\n    layers.BatchNormalization(),\n    layers.MaxPooling2D((2, 2)),\n\n    layers.GlobalAveragePooling2D(name='global_average_pooling'), # Mengurangi dimensi spasial menjadi satu vektor\n    layers.BatchNormalization(name='head_bn2'), # Normalisasi batch untuk stabilitas training\n    layers.Dropout(0.4, name='head_dropout1'), # Regularisasi untuk mencegah overfitting\n    \n    layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n    layers.BatchNormalization(),\n    layers.Dropout(0.5),\n\n    layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n    layers.Dense(num_class, activation='softmax'),\n    layers.Dropout(0.3)\n])\n\n# Kompilasi Model\noptimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n# optimizer = tf.keras.optimizers.RMSprop(learning_rate=1e-4)\nmodel.compile(optimizer=optimizer,\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Menampilkan Summary Model\nmodel.summary()","metadata":{"trusted":true,"id":"INo56gbGLCzS","outputId":"c5e8e423-738c-4ed6-85bc-9fb17d546e1a","colab":{"base_uri":"https://localhost:8080/","height":657}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Membuat direktori checkpoint model\ncheckpoint_path = \"/kaggle/working/pretrain_mnet/model.keras\"\ncheckpoint_dir = os.path.dirname(checkpoint_path)\n\n# Create a callback that saves the model's weights\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n                                                 monitor='val_accuracy',\n                                                 mode='max',\n                                                 save_freq='epoch',\n                                                 verbose=1)","metadata":{"trusted":true,"id":"saQFB_jgLCzS"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"earlystop = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss',\n    patience=5,\n    restore_best_weights=True\n)","metadata":{"id":"b_Ac3SDIU0H_","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from keras.callbacks import ReduceLROnPlateau\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.0001, patience=5, min_lr=0.0001, verbose=1)","metadata":{"id":"iz12by2mVACi","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate the number of steps per epoch and validation steps\ntrain_steps_per_epoch = tf.data.experimental.cardinality(train_ds_aug).numpy()\nval_steps_per_epoch = tf.data.experimental.cardinality(val_ds).numpy()\n\nhistory = model.fit(\n      train_ds_aug,\n      steps_per_epoch=train_steps_per_epoch,  # berapa batch yang akan dieksekusi pada setiap epoch\n      epochs=32,\n      validation_data=val_ds, # menampilkan akurasi pengujian data validasi\n      validation_steps=val_steps_per_epoch,  # berapa batch yang akan dieksekusi pada setiap epoch\n      verbose=1,\n      callbacks=[earlystop, checkpoint, reduce_lr])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nHLu_THXPIcU","outputId":"2bd3f891-4629-453e-e93a-fd9d07bd0fed","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Define accuracy and loss\nacc = history.history['accuracy']\nval_acc = history.history.get('val_accuracy', [])\nloss = history.history['loss']\nval_loss = history.history.get('val_loss', [])\n\n# Ambil panjang minimal\nmin_len = min(len(acc), len(val_acc), len(loss), len(val_loss))\nepochs = range(min_len)\n\n# Potong agar sama panjang\nacc = acc[:min_len]\nval_acc = val_acc[:min_len]\nloss = loss[:min_len]\nval_loss = val_loss[:min_len]\n\n# Plotting\nfig, ax = plt.subplots(1, 2, figsize=(12, 4))\n\n# Accuracy\nax[0].plot(epochs, acc, 'r', label='Training Accuracy')\nax[0].plot(epochs, val_acc, 'b', label='Validation Accuracy')\nax[0].set_title('Training and Validation Accuracy CNN')\nax[0].set_xlabel('Epoch')\nax[0].set_ylabel('Accuracy')\nax[0].legend(loc='upper left')\n\n# Loss\nax[1].plot(epochs, loss, 'r', label='Training Loss')\nax[1].plot(epochs, val_loss, 'b', label='Validation Loss')\nax[1].set_title('Training and Validation Loss CNN')\nax[1].set_xlabel('Epoch')\nax[1].set_ylabel('Loss')\nax[1].legend(loc='upper left')\n\nplt.show()","metadata":{"trusted":true,"id":"kPnzWYl1LCzT"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Inisialisasi list untuk menyimpan label sebenarnya (y_true) dan prediksi (y_pred)\ny_true = []\ny_pred = []\n\n# Lakukan prediksi pada dataset testing\n# Iterasi melalui setiap batch dalam test_ds\nfor images, labels in test_ds:\n    # Lakukan prediksi menggunakan model Anda\n    # verbose=0 agar tidak mencetak progress bar per batch\n    preds = model.predict(images, verbose=0)\n    # Konversi label sebenarnya (one-hot encoded) ke indeks kelas\n    y_true.extend(np.argmax(labels.numpy(), axis=1))\n    # Konversi prediksi (probabilitas) ke indeks kelas dengan probabilitas tertinggi\n    y_pred.extend(np.argmax(preds, axis=1))\n\n# Konversi list ke numpy array untuk perhitungan metrik\ny_true = np.array(y_true)\ny_pred = np.array(y_pred)\n\n# ========== Confusion Matrix ==========\n# Hitung Confusion Matrix\ncm = confusion_matrix(y_true, y_pred)\n\n# Buat DataFrame untuk visualisasi yang lebih baik dengan nama kelas\ndf_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n\n# Visualisasikan Confusion Matrix menggunakan seaborn heatmap\n\nplt.figure(figsize=(10, 7)) # Atur ukuran plot\nsns.heatmap(df_cm, annot=True, fmt='d', cmap='Blues', cbar=False, linewidths=.5, linecolor='black')\nplt.xlabel('Predicted Label', fontsize=14)\nplt.ylabel('True Label', fontsize=14)\n\nplt.title('Confusion Matrix', fontsize=16)\nplt.xticks(rotation=45, ha='right') # Putar label sumbu x agar tidak tumpang tindih\nplt.yticks(rotation=0) # Pastikan label sumbu y tetap horizontal\nplt.tight_layout() # Sesuaikan layout\n\nplt.show()","metadata":{"trusted":true,"id":"zVrnlrkfLCzT"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ========== Classification Report ==========\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_true, y_pred, target_names=class_names))","metadata":{"trusted":true,"id":"QkWXEKhSLCzT"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Saved_Model\nsave_path = 'saved_model/'\nmodel.export(save_path)","metadata":{"id":"r9ZKx5rZTfdZ","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# HDF5\nmodel.save(\"model.h5\")","metadata":{"id":"JNrKLyL1Tfwj","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install tensorflowjs","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!tensorflowjs_converter --input_format=tf_saved_model saved_model/ modeltfjs/","metadata":{"id":"0XOmxZSRTgut","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\n\n# Ambil SavedModel\nconverter = tf.lite.TFLiteConverter.from_saved_model('saved_model/')\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]  # opsional, untuk compress\ntflite_model = converter.convert()\n\n# Simpan file TFLite\nwith open('model.tflite', 'wb') as f:\n    f.write(tflite_model)\n\nprint(\"Berhasil convert ke TFLite!\")","metadata":{"id":"IJ8jAxxWTiiH","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open('labels.txt', 'w') as f:\n    for label in class_names:\n        f.write(f\"{label}\\n\")\n\nprint(\"Label classes saved!\")","metadata":{"id":"S-kqeRjYTp-x","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!zip -r model_bundle.zip model.tflite labels.txt modeltfjs/ model.h5\nprint(\"Model Succesfully Compressed\")","metadata":{"id":"p-4P-9n9TrLh","trusted":true},"outputs":[],"execution_count":null}]}